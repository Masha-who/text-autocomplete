{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb225be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data_utils import load_and_preprocess, split_data\n",
    "from src.next_token_dataset import NextTokenDataset\n",
    "from src.lstm_model import LSTMAutocomplete\n",
    "from src.lstm_train import LSTMTrainer\n",
    "from src.eval_lstm import evaluate_rouge\n",
    "from src.eval_transformer_pipeline import evaluate_gpt2_rouge\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eece79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/lstm.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "RANDOM_STATE = config[\"general\"][\"random_state\"] #42\n",
    "\n",
    "NUM_EPOCHS = config[\"training\"][\"num_epochs\"] #3\n",
    "\n",
    "SEQ_LEN = config[\"data\"][\"seq_len\"] #20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48556c90",
   "metadata": {},
   "source": [
    "Выполним загрузку и обработку текстовых данных, просмотрим первые строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86cf4eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awww that s a bummer you shoulda got david car...\n",
       "1    is upset that he can t update his facebook by ...\n",
       "2    i dived many times for the ball managed to sav...\n",
       "3       my whole body feels itchy and like its on fire\n",
       "4    no it s not behaving at all i m mad why am i h...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_and_preprocess(\"data/raw_dataset.txt\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b999302",
   "metadata": {},
   "source": [
    "Выполним разбиение на обучающую, тренировочную и валидационную выборки и выведем их размер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b0f9e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1280901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "160113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "160113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_texts, val_texts, test_texts = split_data(df, RANDOM_STATE)\n",
    "\n",
    "display(len(df))\n",
    "display(len(train_texts))\n",
    "display(len(test_texts))\n",
    "display(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25eb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем токенизатор\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# тренировочный, тестовый и валидационный датасеты\n",
    "train_dataset = NextTokenDataset(train_texts, tokenizer, seq_len=SEQ_LEN)\n",
    "test_dataset = NextTokenDataset(test_texts, tokenizer, seq_len=SEQ_LEN)\n",
    "val_dataset = NextTokenDataset(val_texts, tokenizer, seq_len=SEQ_LEN)\n",
    "\n",
    "# даталоадеры\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256) \n",
    "test_loader = DataLoader(test_dataset, batch_size=256) \n",
    "\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c9d301",
   "metadata": {},
   "source": [
    "Создадим и обучим первую модель. Ее параметры: \n",
    "hidden_dim=128, batch=256, lr=1e-3, без dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0235521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [04:02<00:00, 36.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 5.487 | Val Loss: 5.266\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [11:18<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0640\n",
      "rouge2: 0.0061\n",
      "rougeL: 0.0628\n",
      "rougeLsum: 0.0628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [04:01<00:00, 36.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 5.026 | Val Loss: 5.179\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [10:45<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0624\n",
      "rouge2: 0.0061\n",
      "rougeL: 0.0611\n",
      "rougeLsum: 0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [04:00<00:00, 36.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 4.891 | Val Loss: 5.163\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [11:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0662\n",
      "rouge2: 0.0067\n",
      "rougeL: 0.0648\n",
      "rougeLsum: 0.0648\n"
     ]
    }
   ],
   "source": [
    "# создаем и обучаем модель\n",
    "model1 = LSTMAutocomplete(vocab_size, hidden_dim=128, eos_token_id=tokenizer.sep_token_id)\n",
    "trainer = LSTMTrainer(model1, tokenizer, vocab_size)\n",
    "\n",
    "trainer.fit(train_loader, val_loader, n_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b65748",
   "metadata": {},
   "source": [
    "Рассмотрим сгенерированные токены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1fe3440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним веса\n",
    "PATH = 'models/128_1e-3_nDO.pth'\n",
    "torch.save(model1.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c8cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to go to\n",
      "my body feels like i\n",
      "you shoulda got a new\n"
     ]
    }
   ],
   "source": [
    "# сгенерируем несколько токенов\n",
    "prefix = torch.tensor(tokenizer.encode(\"i want to\", add_special_tokens=False))\n",
    "generated_ids = model1.generate(prefix, max_new_tokens=2)\n",
    "print(tokenizer.decode(generated_ids.tolist()))\n",
    "\n",
    "prefix = torch.tensor(tokenizer.encode(\"my body feels\", add_special_tokens=False))\n",
    "generated_ids = model1.generate(prefix, max_new_tokens=2)\n",
    "print(tokenizer.decode(generated_ids.tolist()))\n",
    "\n",
    "prefix = torch.tensor(tokenizer.encode(\"you shoulda got\", add_special_tokens=False))\n",
    "generated_ids = model1.generate(prefix, max_new_tokens=2)\n",
    "print(tokenizer.decode(generated_ids.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393bc4b",
   "metadata": {},
   "source": [
    "Заметим, что метрика ROUGE указывает на далеко не самые лучшие результаты, но генерация выглядит довольно осмысленно.\n",
    "\n",
    "Первая модель обучена. Теперь проведем подбор параметров. Выше мы обучали модель со следующими параметрами:\n",
    "1. hidden_dim=128, batch=256, lr=1e-3, без dropout \n",
    "Видно, как отскакивает loss.\n",
    "\n",
    "Сравним со следующими параметрами:\n",
    "\n",
    "2. hidden_dim=128, batch=256, lr=5e-4, dropout=0.3 - сравним, будет ли обучаться стабильнее\n",
    "3. hidden_dim=256, batch=256, lr=1e-3, без dropout - посмотрим, будут ли улучшения в связи с увеличением сложности модели\n",
    "4. hidden_dim=256, batch=256, lr=5e-4, dropout=0.3 - добавим дропаут, понаблюдаем за стабильностью обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e07875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "128_5e-4_DO\n",
      "==============================\n",
      "Device: cuda\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [04:08<00:00, 35.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 6.263 | Val Loss: 5.636\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [12:20<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0665\n",
      "rouge2: 0.0058\n",
      "rougeL: 0.0654\n",
      "rougeLsum: 0.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [04:10<00:00, 35.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 5.463 | Val Loss: 5.340\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [11:57<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0642\n",
      "rouge2: 0.0064\n",
      "rougeL: 0.0630\n",
      "rougeLsum: 0.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [04:13<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 5.265 | Val Loss: 5.232\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [12:07<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0685\n",
      "rouge2: 0.0070\n",
      "rougeL: 0.0671\n",
      "rougeLsum: 0.0671\n",
      "i want to go to\n",
      "my body feels like i\n",
      "you shoulda got a new\n",
      "==============================\n",
      "256_1e-3_nDO\n",
      "==============================\n",
      "Device: cuda\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [05:24<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 5.202 | Val Loss: 5.096\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [14:43<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0655\n",
      "rouge2: 0.0067\n",
      "rougeL: 0.0642\n",
      "rougeLsum: 0.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [05:30<00:00, 26.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 4.712 | Val Loss: 5.084\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [13:31<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0686\n",
      "rouge2: 0.0074\n",
      "rougeL: 0.0673\n",
      "rougeLsum: 0.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [05:26<00:00, 27.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 4.541 | Val Loss: 5.126\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [13:43<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0678\n",
      "rouge2: 0.0074\n",
      "rougeL: 0.0664\n",
      "rougeLsum: 0.0664\n",
      "i want to go to\n",
      "my body feels like i\n",
      "you shoulda got a new\n",
      "==============================\n",
      "256_5e-4_DO\n",
      "==============================\n",
      "Device: cuda\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [05:38<00:00, 26.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 5.846 | Val Loss: 5.294\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [17:15<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0649\n",
      "rouge2: 0.0065\n",
      "rougeL: 0.0636\n",
      "rougeLsum: 0.0636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [05:37<00:00, 26.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 5.117 | Val Loss: 5.085\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [17:07<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0699\n",
      "rouge2: 0.0074\n",
      "rougeL: 0.0685\n",
      "rougeLsum: 0.0685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8824/8824 [05:38<00:00, 26.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 4.926 | Val Loss: 5.017\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1118/1118 [17:17<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0705\n",
      "rouge2: 0.0077\n",
      "rougeL: 0.0690\n",
      "rougeLsum: 0.0690\n",
      "i want to go to\n",
      "my body feels like i\n",
      "you shoulda got a new\n"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    {\"name\": \"128_5e-4_DO\", \"hidden_dim\": 128, \"lr\": 5e-4, \"dropout\": 0.3, \"num_layers\": 2},\n",
    "    {\"name\": \"256_1e-3_nDO\",  \"hidden_dim\": 256, \"lr\": 1e-3, \"dropout\": 0.0, \"num_layers\": 1},\n",
    "    {\"name\": \"256_5e-4_DO\", \"hidden_dim\": 256, \"lr\": 5e-4, \"dropout\": 0.3, \"num_layers\": 2},\n",
    "]\n",
    "\n",
    "for par in params:\n",
    "    print(\"=\" * 30)\n",
    "    print(par[\"name\"])\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    model = LSTMAutocomplete(vocab_size, hidden_dim=par[\"hidden_dim\"], eos_token_id=tokenizer.sep_token_id, dropout=par[\"dropout\"], num_layers=par[\"num_layers\"])\n",
    "    trainer = LSTMTrainer(model, tokenizer, vocab_size, lr=par[\"lr\"])\n",
    "\n",
    "    trainer.fit(train_loader, val_loader, n_epochs=NUM_EPOCHS)\n",
    "\n",
    "    # сохраним веса\n",
    "    PATH = 'models/' + par[\"name\"] + '.pth'\n",
    "    torch.save(model.state_dict(), PATH)    \n",
    "\n",
    "    # сгенерируем несколько токенов\n",
    "    prefix = torch.tensor(tokenizer.encode(\"i want to\", add_special_tokens=False))\n",
    "    generated_ids = model.generate(prefix, max_new_tokens=2)\n",
    "    print(tokenizer.decode(generated_ids.tolist()))\n",
    "\n",
    "    prefix = torch.tensor(tokenizer.encode(\"my body feels\", add_special_tokens=False))\n",
    "    generated_ids = model.generate(prefix, max_new_tokens=2)\n",
    "    print(tokenizer.decode(generated_ids.tolist()))\n",
    "\n",
    "    prefix = torch.tensor(tokenizer.encode(\"you shoulda got\", add_special_tokens=False))\n",
    "    generated_ids = model.generate(prefix, max_new_tokens=2)\n",
    "    print(tokenizer.decode(generated_ids.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5da9845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to talk about\n",
      "my body feels very hot\n",
      "you shoulda got a new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/160113 [00:00<30:32, 87.36it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 160113/160113 [32:48<00:00, 81.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: GPT2 ROUGE\n",
      "rouge1: 0.0579\n",
      "rouge2: 0.0064\n",
      "rougeL: 0.0579\n",
      "rougeLsum: 0.0578\n"
     ]
    }
   ],
   "source": [
    "# 1) Загрузка токенизатора и модели\n",
    "model_name = \"distilgpt2\"          # лёгкая версия GPT-2\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(model_name)\n",
    "model_gpt = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 2) Создаём pipeline для генерации\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model_gpt,\n",
    "    tokenizer=tokenizer_gpt,\n",
    "    device=0  # -1 = CPU; 0 = первый GPU (если есть)\n",
    ")\n",
    "\n",
    "# 3) Тестовые промпты\n",
    "prompts = [\"i want to\", \"my body feels\", \"you shoulda got\"]\n",
    "\n",
    "# 4) Генерируем продолжения\n",
    "for p in prompts:\n",
    "    out = generator(\n",
    "        p,\n",
    "        max_new_tokens=2,       # итоговая длина (включая prompt)\n",
    "        num_return_sequences=1,\n",
    "        do_sample=True,      # стохастическая генерация\n",
    "        top_p=0.95,          # nucleus sampling\n",
    "        temperature=0.8\n",
    "    )\n",
    "\n",
    "    print(out[0][\"generated_text\"]) \n",
    "\n",
    "# оцениваем \"изкоробочный\" трансформер\n",
    "results_gpt = evaluate_gpt2_rouge(\n",
    "    generator=generator,\n",
    "    texts=val_texts,\n",
    "    tokenizer=tokenizer_gpt,\n",
    "    max_new_tokens=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4617fc",
   "metadata": {},
   "source": [
    "ВЫБОР ЛУЧШЕЙ МОДЕЛИ\n",
    "\n",
    "Рассмотрим результаты обучения моделей.\n",
    "\n",
    "Модель 1 показывает стабильное обучение, качество среднее, при ручном просмотре результат генерации пригоден для использования.\n",
    "\n",
    "Модель 2 отличается дропаутом, но метрики практически не отличаются. Возможно, дропаут не дает результатов ввиду той же размерности.\n",
    "\n",
    "Модель 3 с hidden_dim=256 без дропаута демонстрирует улучшение качества по метрикам. Ручной просмотр сгенерированных примеров показывает такие же, как для предыдущих двух моделей, результаты.\n",
    "\n",
    "Модель 4 с hidden_dim=256 с дропаутом показывает еще больше улучшения по метрикам, но просмотр сгенерированных данных вручную показал те же результаты. Нужно отметить, что данная модель самая \"тяжелая\" и медленнее всего обучается.\n",
    "\n",
    "Предобученная модель distilgpt2 показывает результаты хуже. Просмотр сгенерированных вручную результатов также показывает, что несмотря на пригодность distilgpt2 в целом, LSTM модели дают более натуральный с точки зрения ожиданий результат. Вероятно, это можно объяснить тем, что distilgpt2 не дообучалась на исходном датасете (данные могли различаться по стилю и т.д.). \n",
    "\n",
    "ВЫВОДЫ:\n",
    "\n",
    "Так как по условиям задачи ввиду использования на мобильных устройствах необходимо выбрать самую легковесную модель, предлагается модель 1 со следующими характеристиками: hidden_dim=128, batch=256, lr=1e-3, без dropout.\n",
    "\n",
    "distilgpt2 значительно тяжелее и плохо подошла бы для мобильных устройств.\n",
    "\n",
    "Примеры предсказаний выбранной модели из запуска выше:\n",
    "i want to go to\n",
    "my body feels like i\n",
    "you shoulda got a new\n",
    "\n",
    "Данные предсказания подходят для коммуникаций в социальных сетях.\n",
    "\n",
    "Рассмотрим метрику ROUGE для выбранной модели на тестовом датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff62359c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1108/1108 [10:54<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\n",
      "rouge1: 0.0655\n",
      "rouge2: 0.0065\n",
      "rougeL: 0.0642\n",
      "rougeLsum: 0.0642\n"
     ]
    }
   ],
   "source": [
    "# ROUGE на тестовой выборке для лучшей модели\n",
    "rouge_scores_best = evaluate_rouge(\n",
    "                model1, test_loader, tokenizer\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feb82d7",
   "metadata": {},
   "source": [
    "Тестовые метрики близки к валидационным: можно сделать вывод, что модель способна обобщать.\n",
    "\n",
    "Данная модель является рабочим компромиссом между качеством и легкостью, пригодна для автодополнения на мобильных устройствах."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311gpu (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
